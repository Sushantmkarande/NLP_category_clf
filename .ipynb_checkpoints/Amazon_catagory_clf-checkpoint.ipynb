{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40213, 4)\n",
      "(60321, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('hm_train.csv')\n",
    "X_test = pd.read_csv('hm_test.csv')\n",
    "X_test_copy = X_test.copy()\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "affection           20880\n",
       "achievement         20274\n",
       "bonding              6561\n",
       "enjoy_the_moment     6508\n",
       "leisure              4242\n",
       "nature               1127\n",
       "exercise              729\n",
       "Name: predicted_category, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.predicted_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data above is very unbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'exercise']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'nature']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'exercise']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'bonding']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'enjoy_the_moment']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'leisure']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'leisure']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'nature']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'nature']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'exercise']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'exercise']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'exercise']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'nature']])\n",
    "X_train = pd.concat([X_train, X_train[X_train['predicted_category'] == 'bonding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonding             26244\n",
       "exercise            23328\n",
       "affection           20880\n",
       "achievement         20274\n",
       "nature              18032\n",
       "leisure             16968\n",
       "enjoy_the_moment    13016\n",
       "Name: predicted_category, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.predicted_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns=['hmid', 'reflection_period', 'num_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_hm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cleaned_hm\n",
       "0  I went on a successful date with someone I fel...\n",
       "1  I was happy when my son got 90% marks in his e...\n",
       "2       I went to the gym this morning and did yoga.\n",
       "3  We had a serious talk with some friends of our...\n",
       "4  I went with grandchildren to butterfly display..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = X_train.predicted_category\n",
    "X_train = X_train.drop(columns=['hmid', 'reflection_period', 'num_sentence', 'predicted_category'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138742, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138742,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonding             26244\n",
       "exercise            23328\n",
       "affection           20880\n",
       "achievement         20274\n",
       "nature              18032\n",
       "leisure             16968\n",
       "enjoy_the_moment    13016\n",
       "Name: predicted_category, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40213, 1)\n",
      "(138742, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def text_prepare(text):\n",
    "  \n",
    "    text = text.lower() \n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) \n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.cleaned_hm = X_train.cleaned_hm.apply(text_prepare)\n",
    "X_test.cleaned_hm = X_test.cleaned_hm.apply(text_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('happy', 6815), ('got', 5270), ('made', 4213), ('time', 3659)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_counts = {}\n",
    "words_counts = {}\n",
    "\n",
    "from collections import Counter\n",
    "tags_counts = Counter([word for line in X_train.cleaned_hm for word in line.split(' ')])\n",
    "words_counts = Counter([word for line in X_test.cleaned_hm for word in line.split(' ')])\n",
    "most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "words_counts.most_common(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('happy', 6815), ('got', 5270), ('made', 4213)]\n",
      "[('happy', 22768), ('went', 22688), ('got', 14399)]\n"
     ]
    }
   ],
   "source": [
    "print(most_common_words)\n",
    "print(most_common_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a bag of words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "VOCAB = words_counts.most_common(DICT_SIZE)\n",
    "WORDS_TO_INDEX = {item[0]:ii for ii, item in enumerate(sorted(VOCAB, key=lambda x: x[1], reverse=True))}\n",
    "INDEX_TO_WORDS = {ii:word for word, ii in WORDS_TO_INDEX.items()} \n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    result_vector = np.zeros(dict_size)\n",
    " \n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went successful date someone felt sympathy connection'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.cleaned_hm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "mtx = [sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train.cleaned_hm[0]]\n",
    "mtx_1 = [sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train.cleaned_hm[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train.cleaned_hm])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test.cleaned_hm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(INDEX_TO_WORDS)\n",
    "# len(WORDS_TO_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (138742, 5000)\n",
      "X_test shape  (40213, 5000)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mybag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = X_train_mybag[1].toarray()[0]\n",
    "non_zero_elements_count = np.sum([1 for item in row if item != 0])\n",
    "non_zero_elements_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sush/bs4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9446826912681539\n",
      "0.961366933049832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train_mybag, y_train, \n",
    "                                                                            test_size=0.2)\n",
    "\n",
    "model = OneVsRestClassifier(LogisticRegression(penalty='l2', C=1.0))\n",
    "model.fit(X_train_split, y_train_split)\n",
    "print(model.score(X_test_split, y_test_split))\n",
    "print(model.score(X_train_split, y_train_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sush/bs4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = OneVsRestClassifier(LogisticRegression(penalty='l2', C=1.0))\n",
    "model.fit(X_train_mybag, y_train)\n",
    "\n",
    "X_test_copy['predicted_category'] = model.predict(X_test_mybag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40213, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_copy = X_test_copy.drop(columns=['cleaned_hm', 'num_sentence', 'reflection_period'])\n",
    "X_test_copy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs4",
   "language": "python",
   "name": "bs4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
